{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ivi/ilps/personal/svakule/spoken_qa/models/msmarco-distilbert-base-tas-b-cos_sim-msmarco-512-512-augmented\n"
     ]
    }
   ],
   "source": [
    "import pathlib, os\n",
    "from utils import model_path, data_path\n",
    "\n",
    "model_name = \"msmarco-distilbert-base-tas-b\"  # msmarco-distilbert-base-tas-b msmarco-distilbert-base-v3\n",
    "similarity = 'cos_sim'  # dot cos_sim\n",
    "\n",
    "dataset = 'msmarco'\n",
    "data_path = os.path.join(data_path, dataset)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "NEPOCHS = 512\n",
    "LABEL = 'augmented'\n",
    "\n",
    "#### Provide model save path\n",
    "new_model_name = \"{}-{}-{}-{}-{}-{}\".format(model_name.split('/')[-1], similarity, dataset,\n",
    "                                            NEPOCHS, BATCH_SIZE, LABEL)\n",
    "model_save_path = os.path.join(model_path, new_model_name)\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "print(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset for training\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"train\")\n",
    "\n",
    "print(len(queries), 'original queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupt queries\n",
    "import augly.text as textaugs\n",
    "\n",
    "nqueries = 3000\n",
    "\n",
    "corrupted_queries, new_qrels = {}, {}\n",
    "for q_id, q in queries.items():\n",
    "    new_q = textaugs.simulate_typos(q)\n",
    "    corrupted_queries[q_id] = new_q  # just overwrite the original query\n",
    "    new_qrels[q_id] = qrels[q_id]\n",
    "    \n",
    "print(len(corrupted_queries), 'corrupted queries')\n",
    "\n",
    "queries = corrupted_queries\n",
    "qrels = new_qrels\n",
    "print(len(queries), 'corrupted queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample training script from https://github.com/UKPLab/beir/blob/main/examples/retrieval/training/train_sbert.py\n",
    "from sentence_transformers import losses, models, SentenceTransformer\n",
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.train import TrainRetriever\n",
    "\n",
    "#### Provide any sentence-transformers or HF model\n",
    "# model_name = \"distilbert-base-uncased\" \n",
    "# word_embedding_model = models.Transformer(model_name, max_seq_length=350)\n",
    "# pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "# model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "#### Or provide pretrained sentence-transformer model\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "retriever = TrainRetriever(model=model, batch_size=16)\n",
    "\n",
    "#### Prepare training samples\n",
    "train_samples = retriever.load_train(corpus, queries, qrels)\n",
    "train_dataloader = retriever.prepare_train(train_samples, shuffle=True)\n",
    "\n",
    "#### Training SBERT with cosine-product\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=retriever.model)\n",
    "#### training SBERT with dot-product\n",
    "# train_loss = losses.MultipleNegativesRankingLoss(model=retriever.model, similarity_fct=util.dot_score)\n",
    "\n",
    "#### Prepare dev evaluator\n",
    "# ir_evaluator = retriever.load_ir_evaluator(dev_corpus, dev_queries, dev_qrels)\n",
    "\n",
    "#### If no dev set is present from above use dummy evaluator\n",
    "ir_evaluator = retriever.load_dummy_evaluator()\n",
    "\n",
    "#### Configure Train params\n",
    "num_epochs = 1\n",
    "evaluation_steps = 5000\n",
    "warmup_steps = int(len(train_samples) * num_epochs / retriever.batch_size * 0.1)\n",
    "\n",
    "retriever.fit(train_objectives=[(train_dataloader, train_loss)], \n",
    "                evaluator=ir_evaluator, \n",
    "                epochs=num_epochs,\n",
    "                output_path=model_save_path,\n",
    "                warmup_steps=warmup_steps,\n",
    "                evaluation_steps=evaluation_steps,\n",
    "                save_best_model=True,\n",
    "                use_amp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "model = DRES(models.SentenceBERT(model_save_path))\n",
    "similarities = ['cos_sim', 'dot']\n",
    "\n",
    "# wiggle similarity function at inference time\n",
    "for similarity in similarities:\n",
    "    print(model_name, similarity)\n",
    "    retriever = EvaluateRetrieval(model, score_function=similarity)\n",
    "\n",
    "    corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n",
    "\n",
    "    results = retriever.retrieve(corpus, queries)\n",
    "    ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "    print(ndcg, _map, recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

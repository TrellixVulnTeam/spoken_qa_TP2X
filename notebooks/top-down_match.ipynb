{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28497 entity labels\n"
     ]
    }
   ],
   "source": [
    "# load entities\n",
    "import json\n",
    "\n",
    "path = '../data/'\n",
    "\n",
    "with open(path+'entities.json', 'r') as fin:\n",
    "    entities = json.load(fin)\n",
    "print(len(entities), 'entity labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is a film directed by wiebke von carolsfeld\n",
      "WIEBKE CAROLSFELD\n"
     ]
    }
   ],
   "source": [
    "# load original question\n",
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "\n",
    "path = '../data/'\n",
    "with open(path+'annotated_wd_data_valid_answerable.txt') as fin:\n",
    "    lines = fin.readlines()\n",
    "    l = lines[1]\n",
    "#         subject [tab] property [tab] object [tab] question\n",
    "    s, p, o, q = l.strip('\\n').split('\\t')\n",
    "    q = re.sub(chars_to_ignore_regex, '', q).lower()\n",
    "    print(q)\n",
    "    s_label = entities[s]\n",
    "    s_label = re.sub(chars_to_ignore_regex, '', s_label).upper()\n",
    "    print(s_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  6, 10],\n",
      "        [ 0,  6, 10],\n",
      "        [ 0,  6, 10],\n",
      "        ...,\n",
      "        [ 0,  6,  4],\n",
      "        [ 0,  6,  4],\n",
      "        [ 0,  6,  4]])\n",
      "torch.Size([365, 3])\n"
     ]
    }
   ],
   "source": [
    "# match entity label to the ctc table\n",
    "import os\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "path = \"../data/dev/\"\n",
    "\n",
    "file = '2.wav'\n",
    "speech, samplerate = sf.read(path+file)\n",
    "i = int(file.split('.')[0]) - 1\n",
    "\n",
    "input_values = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# find where s_tokens appear in the table\n",
    "ctc_table = torch.topk(logits, k=3, dim=-1)\n",
    "predicted_ids = ctc_table.indices[0]\n",
    "# predicted_ids = torch.argmax(logits, dim=-1).indices\n",
    "\n",
    "print(predicted_ids)\n",
    "print(predicted_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'I', 'E', 'B', 'K', 'E', '|', 'C', 'A', 'R', 'O', 'L', 'S', 'F', 'E', 'L', 'D']\n",
      "[18, 10, 5, 24, 26, 5, 4, 19, 7, 13, 8, 15, 12, 20, 5, 15, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'WIEBKE CAROLSFELD'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode entity label\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "tokenizer = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "s_tokens = tokenizer.tokenizer._tokenize(s_label)\n",
    "print(s_tokens)\n",
    "s_tokens = tokenizer.tokenizer(s_label)['input_ids']\n",
    "print(s_tokens)\n",
    "# print(s_tokens[6])  # delimeter 4\n",
    "# print(tokenizer.tokenizer.pad_token)  # CTC-blank token 0\n",
    "# print(tokenizer.tokenizer._convert_token_to_id('<pad>'))\n",
    "tokenizer.tokenizer._decode(s_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.5266, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# produce a score for the label\n",
    "score = 0\n",
    "ind = 0\n",
    "length = 4\n",
    "for token_id in s_tokens[:length]:\n",
    "    matched_positions = (predicted_ids == torch.Tensor([token_id])).nonzero(as_tuple=True)\n",
    "    predicted_values = ctc_table.values[0][matched_positions[0], matched_positions[1]]\n",
    "    # sort positions by logits\n",
    "    logits, indices = torch.sort(predicted_values, descending=True)\n",
    "    if matched_positions[0][indices][0] > ind:\n",
    "        ind = matched_positions[0][indices][0]\n",
    "        score += logits[0]\n",
    "\n",
    "print(score/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 25, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SVETA'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode negative label\n",
    "n_label = 'SVETA'\n",
    "n_tokens = tokenizer.tokenizer(n_label)['input_ids']\n",
    "print(n_tokens)\n",
    "tokenizer.tokenizer._decode(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0855, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# produce a score for the label\n",
    "score = 0\n",
    "ind = 0\n",
    "for token_id in n_tokens[:length]:\n",
    "    matched_positions = (predicted_ids == torch.Tensor([token_id])).nonzero(as_tuple=True)\n",
    "    predicted_values = ctc_table.values[0][matched_positions[0], matched_positions[1]]\n",
    "    # sort positions by logits\n",
    "    logits, indices = torch.sort(predicted_values, descending=True)\n",
    "    if matched_positions[0][indices][0] > ind:\n",
    "        ind = matched_positions[0][indices][0]\n",
    "        score += logits[0]\n",
    "\n",
    "print(score/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

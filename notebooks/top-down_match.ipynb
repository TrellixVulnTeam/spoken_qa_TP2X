{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28497 entity labels\n"
     ]
    }
   ],
   "source": [
    "# load entities\n",
    "import json\n",
    "\n",
    "path = '../data/'\n",
    "\n",
    "with open(path+'entities.json', 'r') as fin:\n",
    "    entities = json.load(fin)\n",
    "print(len(entities), 'entity labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is a film directed by wiebke von carolsfeld\n",
      "WIEBKE CAROLSFELD\n"
     ]
    }
   ],
   "source": [
    "# load original question\n",
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "\n",
    "path = '../data/'\n",
    "with open(path+'annotated_wd_data_valid_answerable.txt') as fin:\n",
    "    lines = fin.readlines()\n",
    "    l = lines[1]\n",
    "#         subject [tab] property [tab] object [tab] question\n",
    "    s, p, o, q = l.strip('\\n').split('\\t')\n",
    "    q = re.sub(chars_to_ignore_regex, '', q).lower()\n",
    "    print(q)\n",
    "    s_label = entities[s]\n",
    "    s_label = re.sub(chars_to_ignore_regex, '', s_label).upper()\n",
    "    print(s_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  6, 10],\n",
      "        [ 0,  6, 10],\n",
      "        [ 0,  6, 10],\n",
      "        ...,\n",
      "        [ 0,  6,  4],\n",
      "        [ 0,  6,  4],\n",
      "        [ 0,  6,  4]])\n",
      "torch.Size([365, 3])\n"
     ]
    }
   ],
   "source": [
    "# match entity label to the ctc table\n",
    "import os\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "path = \"../data/dev/\"\n",
    "\n",
    "file = '2.wav'\n",
    "speech, samplerate = sf.read(path+file)\n",
    "i = int(file.split('.')[0]) - 1\n",
    "\n",
    "input_values = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# find where s_tokens appear in the table\n",
    "ctc_table = torch.topk(logits, k=3, dim=-1)\n",
    "predicted_ids = ctc_table.indices[0]\n",
    "# predicted_ids = torch.argmax(logits, dim=-1).indices\n",
    "\n",
    "print(predicted_ids)\n",
    "print(predicted_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'I', 'E', 'B', 'K', 'E']\n",
      "['C', 'A', 'R', 'O', 'L', 'S', 'F', 'E', 'L', 'D']\n",
      "[[18, 10, 5, 24, 26, 5], [19, 7, 13, 8, 15, 12, 20, 5, 15, 14]]\n"
     ]
    }
   ],
   "source": [
    "# encode entity label\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "tokenizer = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "s_tokens = []\n",
    "for word in s_label.split():\n",
    "    print(tokenizer.tokenizer._tokenize(word))\n",
    "    s_tokens.append(tokenizer.tokenizer(word)['input_ids'])\n",
    "\n",
    "print(s_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 10, 5, 24, 26, 5]\n",
      "tensor(30.9749, grad_fn=<DivBackward0>)\n",
      "[19, 7, 13, 8, 15, 12, 20, 5, 15, 14]\n",
      "tensor(11.3687, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# produce a score for the label\n",
    "length = 4\n",
    "for word in s_tokens:\n",
    "    print(word)\n",
    "    score = 0\n",
    "    ind = 0\n",
    "    for token_id in word:\n",
    "#         print(token_id)\n",
    "        matched_positions = (predicted_ids == torch.Tensor([token_id])).nonzero(as_tuple=True)\n",
    "        predicted_values = ctc_table.values[0][matched_positions[0], matched_positions[1]]\n",
    "        # sort positions by logits\n",
    "        logits, indices = torch.sort(predicted_values, descending=True)\n",
    "#         print(matched_positions[0][indices][:4])\n",
    "#         print(matched_positions[1][indices][:4])\n",
    "#         print(logits[:4])\n",
    "        \n",
    "        # get the cumulative probability of the next letter appearing next\n",
    "        predicted_next = (matched_positions[0][indices][:4] > torch.Tensor([ind])).nonzero(as_tuple=True)[0]\n",
    "#         print(predicted_next)\n",
    "        if predicted_next.nelement() != 0:\n",
    "            cum_p = sum(logits[predicted_next])\n",
    "#             print(predicted_next[0])\n",
    "            ind = matched_positions[0][indices][predicted_next[0]]\n",
    "#             print(ind)\n",
    "            score += cum_p\n",
    "\n",
    "    print(score/len(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 10, 5, 24, 26, 5]\n",
      "18\n",
      "tensor([ 70,  69, 152, 219])\n",
      "tensor([0, 1, 1, 2])\n",
      "tensor([13.7542,  9.9319,  6.7443,  5.8215], grad_fn=<SliceBackward>)\n",
      "10\n",
      "tensor([ 82, 116, 156, 223])\n",
      "tensor([0, 0, 0, 2])\n",
      "tensor([12.0832, 11.4323,  8.8787,  7.1710], grad_fn=<SliceBackward>)\n",
      "5\n",
      "tensor([124, 134, 133, 223])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([14.9721, 12.6955, 10.8439, 10.0854], grad_fn=<SliceBackward>)\n",
      "24\n",
      "tensor([142, 141, 159, 143])\n",
      "tensor([0, 1, 1, 2])\n",
      "tensor([13.2970,  9.3588,  8.0966,  1.5534], grad_fn=<SliceBackward>)\n",
      "26\n",
      "tensor([194, 165])\n",
      "tensor([1, 1])\n",
      "tensor([9.6928, 9.3516], grad_fn=<SliceBackward>)\n",
      "5\n",
      "tensor([124, 134, 133, 223])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([14.9721, 12.6955, 10.8439, 10.0854], grad_fn=<SliceBackward>)\n",
      "tensor(10.6332, grad_fn=<DivBackward0>)\n",
      "[19, 7, 13, 8, 15, 12, 20, 5, 15, 14]\n",
      "19\n",
      "tensor([125, 194, 126, 165])\n",
      "tensor([0, 0, 1, 0])\n",
      "tensor([13.4145, 11.9123, 10.9482, 10.6738], grad_fn=<SliceBackward>)\n",
      "7\n",
      "tensor([ 74, 199,  90, 169])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([13.3510, 10.9035, 10.6074,  9.6432], grad_fn=<SliceBackward>)\n",
      "13\n",
      "tensor([120, 119, 203, 121])\n",
      "tensor([0, 0, 0, 1])\n",
      "tensor([12.2570, 11.6240,  8.8483,  8.5680], grad_fn=<SliceBackward>)\n",
      "8\n",
      "tensor([180, 206, 199,  71])\n",
      "tensor([0, 0, 2, 2])\n",
      "tensor([13.2365,  9.5234,  4.7789,  3.1022], grad_fn=<SliceBackward>)\n",
      "15\n",
      "tensor([226, 225, 229, 227])\n",
      "tensor([0, 1, 2, 1])\n",
      "tensor([6.4284, 4.7242, 4.5898, 3.7438], grad_fn=<SliceBackward>)\n",
      "12\n",
      "tensor([ 83,  84, 214, 215])\n",
      "tensor([0, 1, 0, 1])\n",
      "tensor([11.6684, 10.6109,  9.0200,  5.5867], grad_fn=<SliceBackward>)\n",
      "20\n",
      "tensor([175,  95, 219, 172])\n",
      "tensor([0, 1, 0, 1])\n",
      "tensor([9.9489, 8.1457, 7.3703, 4.3249], grad_fn=<SliceBackward>)\n",
      "5\n",
      "tensor([124, 134, 133, 223])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([14.9721, 12.6955, 10.8439, 10.0854], grad_fn=<SliceBackward>)\n",
      "15\n",
      "tensor([226, 225, 229, 227])\n",
      "tensor([0, 1, 2, 1])\n",
      "tensor([6.4284, 4.7242, 4.5898, 3.7438], grad_fn=<SliceBackward>)\n",
      "14\n",
      "tensor([112, 135, 136, 229])\n",
      "tensor([0, 0, 1, 1])\n",
      "tensor([14.0354, 12.7766, 10.6493,  7.5972], grad_fn=<SliceBackward>)\n",
      "tensor(0.6428, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# produce a score for the label\n",
    "ind = 0\n",
    "length = 4\n",
    "for word in s_tokens:\n",
    "    print(word)\n",
    "    score = 0\n",
    "    for token_id in word:\n",
    "        print(token_id)\n",
    "        matched_positions = (predicted_ids == torch.Tensor([token_id])).nonzero(as_tuple=True)\n",
    "        predicted_values = ctc_table.values[0][matched_positions[0], matched_positions[1]]\n",
    "        # sort positions by logits\n",
    "        logits, indices = torch.sort(predicted_values, descending=True)\n",
    "        print(matched_positions[0][indices][:4])\n",
    "        print(matched_positions[1][indices][:4])\n",
    "        print(logits[:4])\n",
    "        \n",
    "        # get the cumulative probability of the next letter appearing next\n",
    "        if matched_positions[0][indices][0] > ind:\n",
    "            ind = matched_positions[0][indices][0]\n",
    "            score += logits[0]\n",
    "\n",
    "    print(score/len(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.5266, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# produce a score for the label\n",
    "score = 0\n",
    "ind = 0\n",
    "length = 4\n",
    "for token_id in s_tokens[:length]:\n",
    "    matched_positions = (predicted_ids == torch.Tensor([token_id])).nonzero(as_tuple=True)\n",
    "    predicted_values = ctc_table.values[0][matched_positions[0], matched_positions[1]]\n",
    "    # sort positions by logits\n",
    "    logits, indices = torch.sort(predicted_values, descending=True)\n",
    "    if matched_positions[0][indices][0] > ind:\n",
    "        ind = matched_positions[0][indices][0]\n",
    "        score += logits[0]\n",
    "\n",
    "print(score/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6332, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# produce a score for the label\n",
    "score = 0\n",
    "ind = 0\n",
    "length = 6\n",
    "for token_id in s_tokens[:length]:\n",
    "    matched_positions = (predicted_ids == torch.Tensor([token_id])).nonzero(as_tuple=True)\n",
    "    predicted_values = ctc_table.values[0][matched_positions[0], matched_positions[1]]\n",
    "    # sort positions by logits\n",
    "    logits, indices = torch.sort(predicted_values, descending=True)\n",
    "    if matched_positions[0][indices][0] > ind:\n",
    "        ind = matched_positions[0][indices][0]\n",
    "        score += logits[0]\n",
    "\n",
    "print(score/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 25, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SVETA'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode negative label\n",
    "n_label = 'SVETA'\n",
    "n_tokens = tokenizer.tokenizer(n_label)['input_ids']\n",
    "print(n_tokens)\n",
    "tokenizer.tokenizer._decode(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0855, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# produce a score for the label\n",
    "score = 0\n",
    "ind = 0\n",
    "for token_id in n_tokens[:length]:\n",
    "    matched_positions = (predicted_ids == torch.Tensor([token_id])).nonzero(as_tuple=True)\n",
    "    predicted_values = ctc_table.values[0][matched_positions[0], matched_positions[1]]\n",
    "    # sort positions by logits\n",
    "    logits, indices = torch.sort(predicted_values, descending=True)\n",
    "    if matched_positions[0][indices][0] > ind:\n",
    "        ind = matched_positions[0][indices][0]\n",
    "        score += logits[0]\n",
    "\n",
    "print(score/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 2]),)\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([1, 18, 18])\n",
    "print ((t > torch.Tensor([2])).nonzero(as_tuple=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

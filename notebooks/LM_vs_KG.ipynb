{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can LM answer KG's questions?\n",
    "\n",
    "Use questions for Wikidata to retrieve Wikipedia paragraphs with a pre-trained dense retrieval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2681468 passages\n",
      "3452 questions\n"
     ]
    }
   ],
   "source": [
    "# load Wiki passage corpus and questions from NQ\n",
    "import os\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from utils import model_path, data_path\n",
    "\n",
    "dataset = 'nq'\n",
    "data_path = os.path.join(data_path, dataset)\n",
    "\n",
    "nq_corpus, nq_queries, nq_qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n",
    "\n",
    "print(len(nq_corpus), 'passages')\n",
    "print(len(nq_qrels), 'questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded valid split of WD18 with original queries, entities corpus and answers qrels\n",
      "Loaded train split of WD18 with original queries, relations-extra corpus and relations qrels\n",
      "28497 entities\n",
      "8913 relations\n",
      "1316 questions\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data, data_path\n",
    "\n",
    "# load WD18 questions, entities and relations corpus\n",
    "dataset_version = 'WD18_entities_original_answers'  # text answers-all\n",
    "# dataset_version = 'WD18_entities_wav2vec2-large-960h-lv60-self_answers'  # wav2vec2-large-960h-lv60-self BM transcripts\n",
    "e_corpus, wd_queries, wd_qrels = load_data(dataset_version, 'valid', data_path)\n",
    "r_corpus, _, _ = load_data('WD18_relations-extra_original_relations')\n",
    "\n",
    "print(len(e_corpus), 'entities')\n",
    "print(len(r_corpus), 'relations')\n",
    "print(len(wd_qrels), 'questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6246e31b36e144f9b0cc0e8647e33903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/245M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nq-distilbert-base-v1 cos_sim\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0f857368fd44e9876e9d89cc3c6ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea4fbef384a4365a524e7d6fe4811e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9775b0c7b32c44bd9a4a57f2aaa77063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0170441df88d4b29a1aaac16137be782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8bc8f457854d4a92dec02b624c2c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013f53502ecc4d398120b9b0c7fd5d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387fb8ca8ea145f487d3ca8351706e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc734c25b3ea41bd9209568340d06fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6589e8f55c5841b8ad2c173d55259589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d808b6b85449deb905a0d9e9f07e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef85c03a3144626a30cbee5d527f919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0807893bbd4c1d9c286b8d27e05305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f43e2ec2796494a8e3508115e1ebc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777cb11d1fde4948882f31172a1cba5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd803f8f1974a7780361d524418394e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd497725b73345f1b7732f3f64255936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c80e4f49ab4a0988e4356888829d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0677bdc9e0dc4988a0c2ca7403bba5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239458d2612348758de556215c8b5de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc659167e1364730a58fbb97a201cbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45869fe95e6f42edb08e8e3cffe5f0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c0d238f8c2444ea4aeedc2735dc875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472b554849b645b6976729570d2b3a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b358f3239bc453092aa4e0d06488e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e59fa48066c4046a8981d1798e91cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e00bab2ecaa44acb9905e04778a78b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0960218e9240fc998220faa95d2f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b07157712143d4abf1380e7b5dce1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cad23da7d64a2192b0e965307dd921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0e9e674f444a1299b5c570a41fa7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d5739bbe524701a3e276f65a1b944b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceca66a848754112a1aafbaf503c7d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4c893998824dc18d91e9af04190994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168f934d0ec6462abe41a761eb44d41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbc81f6ee3e47629eff3c541150db5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ae4426066c465b9b58a59de807874f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f677ac724d458bb286c966aa2a656e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640e29d340894f168049b5d9c95e9240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e065557503f24d1fb9462d3afde9f9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692a55a10e964f07acc6aafbbfb90eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68f52a2ad9b49789961b0f741259727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0b1f967ca744b7959a8778d50fbc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6add0a273de9474594726c1090594681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784ad369549149b8a55dcffda02a1bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a71a69722649e0b1de5534ad8d2cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cb1458cafe47ab9c6e651b3aa2bb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88147142ad94088a2dc2a6e593719d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6698aa8e24ee4c9b9f4878ced5655b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2826384ce4ba487c9a6196a12619ae9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2993e54f2f2a45cabe217d3ff464a193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaf7259e4124ffabfb8777bba9a4db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbde6f3f9d147c9826d175577b81de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1525b5e9087e4b2cae973ebad1415e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6ebed5f02b489795418c088f8daa71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921ad6eb338845ae9cbc27015f9c2a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval import models\n",
    "\n",
    "model_names = ['msmarco-distilbert-base-tas-b', 'nq-distilbert-base-v1']  # the last one is the best on NQ in beir\n",
    "similarities = ['dot', 'cos_sim']\n",
    "\n",
    "# choose one of the models from the list above\n",
    "i = -1\n",
    "model_name = model_names[i]\n",
    "similarity = similarities[i]\n",
    "\n",
    "# load model\n",
    "model = DRES(models.SentenceBERT(model_name))\n",
    "print(model_name, similarity)\n",
    "\n",
    "# encode everything and retrieve answers\n",
    "retriever = EvaluateRetrieval(model, score_function=similarity)\n",
    "results = retriever.retrieve(nq_corpus, wd_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a film directed by wiebke von carolsfeld?\n",
      "Almost Famous is a 2000 American comedy-drama film written and directed by Cameron Crowe, and starring Billy Crudup, Kate Hudson and Patrick Fugit. It tells the fictional story of a teenage journalist writing for Rolling Stone magazine in the early 1970s while covering the fictitious rock band Stillwater, and his efforts to get his first cover story published. The film is semi-autobiographical, as Crowe himself was a teenage writer for Rolling Stone. 0.1929573267698288\n",
      "The film was shot with two cameras side by side, with one negative edited as a sound film and the other edited as an \"International Sound Version\" for distribution in non-English speaking areas. 0.28667551279067993\n",
      "American Idol was nominated for the Emmy's Outstanding Reality Competition Program for nine years but never won.[216] Director Bruce Gower won a Primetime Emmy Award for Outstanding Directing For A Variety, Music Or Comedy Series in 2009, and the show won a Creative Arts Emmys each in 2007 and 2008, three in 2009, and two in 2011, as well as a Governor's Award in 2007 for its Idol Gives Back edition. It won the People's Choice Award, which honors the popular culture of the previous year as voted by the public, for favorite competition/reality show in 2005, 2006, 2007, 2010, 2011 and 2012.[217] It won the first Critics' Choice Television Award in 2011 for Best Reality Competition.[218] 0.2650523781776428\n",
      "A great number of German Army veterans were living in Los Angeles at the time of filming and were recruited as bit players and technical advisers. Around 2,000 extras were utilized during production.[7] Among them was future director Fred Zinnemann (From Here to Eternity, High Noon, Julia, A Man for All Seasons), who was fired for impudence. 0.23221461474895477\n",
      "In the film, Paul is shot while reaching for a butterfly. This scene is different from the book, and was inspired by an earlier scene showing a butterfly collection in Paul's home. The scene was shot during the editing phase, so the actors were no longer available and Milestone had to use his own hand as Paul's. 0.19676637649536133\n",
      "What was Seymour Parker Gilbert's profession?\n",
      "Eddie Mathews\n",
      "Joe Morgan 0.18148303031921387\n",
      "Monk's CafÃ© is a fictional coffee shop from the NBC sitcom Seinfeld. 0.1840873509645462\n",
      "Jerry Seinfeld and writer Larry David, who created Seinfeld, called the coffee shop Monkâ€™s because there was a poster of the jazz great pianist Thelonious Monk in the office in which they were writing, and they just needed a name.[2] In the original pilot \"The Seinfeld Chronicles,\" the luncheonette was known as Pete's, and featured a waitress named Claire (played by Lee Garlington); Claire was originally conceived as a regular for the show but was written out (and Pete's replaced by Monk's) by the time the show went to series. 0.2069290578365326\n",
      "The octane rating was developed by chemist Russell Marker at the Ethyl Corporation in 1926.[27] The selection of n-heptane as the zero point of the scale was due to its availability in high purity. Other isomers of heptane produced from crude oil have greatly different ratings. 0.19329185783863068\n",
      "The show featured a panel of four celebrities who questioned the contestants. On the initial program of February 2, 1950, the panel was former New Jersey governor Harold Hoffman, columnist Dorothy Kilgallen, poet Louis Untermeyer, and psychiatrist Richard Hoffmann. The panel varied somewhat in the following weeks, but after the first few broadcasts, during the show's earliest period the panel generally consisted of Kilgallen, actress Arlene Francis, Untermeyer and comedy writer Hal Block. At various times, a regular panelist might take a vacation or be absent from an episode to due outside commitments; on these occasions, a guest panelist would take their spot. The most frequent guest panelist was Arlene Francis's husband Martin Gabel, who appeared 112 times over the years. 0.24072812497615814\n",
      "in what french city did antoine de févin die \n",
      "Meanwhile, Merlin discovers that Professor Arnold has returned to work as if nothing had happened. Hart attempts to interrogate him, but a chip in Professor Arnold's neck explodes, killing him. The detonation signal is traced to a facility owned by Internet billionaire and philanthropist Richmond Valentine, who has recently offered everyone in the world SIM cards that grant free lifetime cellular and Internet connectivity. Hart, impersonating a billionaire philanthropist, meets Valentine face-to-face. Hart learns of Valentine's connection to an obscure hate group's church in Kentucky, and travels there, wearing glasses containing a video transceiver. Eggsy watches as Valentine activates the SIM cards in the church, triggering a signal that causes the parishioners to become murderously violent. Hart's spy training leaves him as the only survivor. Outside the church Valentine explains what happened, then shoots Hart in the face. 0.16020002961158752\n",
      "(Valentinian) thought he had slain his master; he found that he had slain his protector: and he fell a helpless victim to the first conspiracy which was hatched against his throne.[191] 0.1666574329137802\n",
      "In the penultimate season three episode \"This Sorrowful Life\", Rick confides in Merle, Daryl, and Hershel that the Governor promises to leave the prison alone if they hand over Michonne. Rick plans to do as the Governor requests and asks Merle to help deliver Michonne to the meeting place at noon. Merle, knowing that Rick will not go through with it, traps and ties up Michonne. However, after he and Michonne talk about personal matters, he lets her go and returns her katana, telling her he has something to do alone. He starts drinking whiskey before using loud music to lure a group of walkers to the exchange site where the Governor is waiting to ambush whoever will show up. The music also distracts the Governor's henchmen while Merle secretly takes cover, intent on killing the Governor both for revenge and to prevent him from killing anyone else at the prison, mainly Daryl. After shooting several of the henchmen, Merle is caught and beaten by Martinez and two other men and then, injured and winded, fights one-on-one with the Governor. The Governor gets the upper hand and bites off two of Merle's fingers. A wounded Merle then yells that he will not beg for mercy before the Governor shoots him in the chest with a pistol. Later on, Daryl, who left the prison to track down Merle and Michonne after Rick noticed them missing, finds Michonne unhurt and continues on to the exchange site, where he sees a reanimated Merle eating Ben's corpse. Daryl breaks down in tears and pushes his reanimated brother away more than once before stabbing him repeatedly in the head, killing him for good. 0.20252032577991486\n",
      "A rich senatorial aristocrat, Petronius Maximus, who had encouraged both murders, then seized the throne. He broke the engagement between Huneric, prince of the Vandals, and Princess Eudocia, and had time to send Avitus to ask for the help of the Visigoths in Gaul[192] before the Vandals sailed to Italy. Petronius was unable to muster any effective response and was killed by a mob as he tried to flee the city. The Vandals entered Rome, and plundered it for two weeks. Despite the shortage of money for the defence of the state, considerable private wealth had accumulated since the previous sack in 410. The Vandals sailed away with large amounts of treasure and also with the Princess Eudocia, who became the wife of one Vandal king and the mother of another.[193] 0.20967745780944824\n",
      "Jean Fernel (1497â€“1558), a French physician, introduced the term \"physiology\".[13] 0.18267880380153656\n",
      "who is the chid of fritz leiber?\n",
      "According to Arvind Sharma, Ambedkar noticed certain flaws in the Aryan invasion theory that were later acknowledged by western scholarship. For example, scholars now acknowledge 0.17618942260742188\n",
      "Upon their arrival, Oobleck discovers that Zwei was hidden in Ruby's backpack, but he allows him to stay. Throughout the day, Team RWBY has to fight Grimm while Oobleck analyses the surroundings and his students. He asks Yang, Weiss and Blake why they wish to become Huntresses. Their answers - Yang's thrill-seeking attitude, the honor of Weiss' family, and Blake's hope of stopping the wrongs in the world - don't satisfy him, leaving the girls unsure of themselves. 0.188601553440094\n",
      "Weiss, Blake and Yang try to cheer up Ruby, who discovers that their father sent them the family's pet dog, Zwei, to look after for a while. An announcement from Glynda gathers all first year students, including the exchange students from Shade, Haven and Atlas Academy. 0.18870709836483002\n",
      "Frederick was born Jesse Frederick James Conaway in Salisbury, Maryland, and was raised in Seaford, Delaware. He was the youngest of two children. His brother, Everett Thomas (Tommy) Conaway, Jr. (1944-1956), died of Cystic Fibrosis at 12 years of age. In his early childhood, Jesse was familiarly known as \"Freddy\" before legally dropping the James Conaway from his name in his later teens. This was done in an attempt to distinguish himself from the legacy of his father, Everett T. \"Conny\" Conaway, Sr. (1915-2010). Conny was a prominent figure in the poultry processing industry. During his unprecedented 70-year career, the senior Conaway designed and built some of the earliest processing plants for Allen Family Foods, Frank Perdue and Preston Townsend, all of which are still operating today. In early adolescence, Frederick attended Massanutten Military Academy for two years. Once he entered high school, his father put him to work, hoping to groom a protege in the industry. Frederick learned about the processing of poultry first hand as a plant laborer at many of his father's factories on the East Coast. 0.2319568693637848\n",
      "The general public has paid respect to a number of individuals lying in state at the Capitol, including numerous former presidents, senators, and other officials. Other Americans lying in honor include Officers Jacob Chestnut and John Gibson, the two officers killed in the 1998 shooting incident. Chestnut was the first African American ever to lie in honor in the Capitol. The public also paid respect to Rosa Parks, an icon of the Civil Rights Movement, at the Capitol in 2005. She was the first woman and second African American to lie in honor in the Capitol. On September 24, 2015, Pope Francis gave a joint address to Congress, the first Pope to do so.[59] 0.17856094241142273\n",
      "What is the language of the invaders?\n",
      "A material's absorption spectrum is the fraction of incident radiation absorbed by the material over a range of frequencies. The absorption spectrum is primarily determined[1][2][3] by the atomic and molecular composition of the material. Radiation is more likely to be absorbed at frequencies that match the energy difference between two quantum mechanical states of the molecules. The absorption that occurs due to a transition between two states is referred to as an absorption line and a spectrum is typically composed of many lines. 0.15432247519493103\n",
      "In the 480's the Alchon Huns under Toramana and Mihirakula broke through the Gupta defenses in the northwest, and much of the empire in the northwest was overrun by the Huns by 500. The empire disintegrated under the attacks of Toramana and his successor Mihirakula. It appears from inscriptions that the Guptas, although their power was much diminished, continued to resist the Huns. The Hun invader Toramana was defeated by Bhanugupta in 510.[47][48] The Huns were defeated and driven out of India in 528 by king Yashodharman from Malwa, and possibly Gupta emperor Narasimhagupta.[49] 0.2659439444541931\n",
      "All the instrumental tracks are amalgams of various sequences and musical cues from the film rather than straight score excerpts. The end credits of the film feature the song \"If You Asked Me To\" sung by Patti LaBelle. Though the song was a top ten R&B charter and a minor pop hit for LaBelle, in 1992, the song was covered by and became a much bigger hit for singer CÃ©line Dion. The track \"Wedding Party\", used during the wedding of Felix Leiter to Della Churchill, makes reference to the track \"Jump Up\" from the first Bond film, Dr. No. 0.17996861040592194\n",
      "A text from the Nahua point of view, the Anales de Tlatelolco, an early indigenous account in Nahuatl, perhaps from 1540, remained in indigenous hands until it was published.[when?] An extract of this important manuscript was published in 1991 by James Lockhart in Nahuatl transcription and English translation.[21] A popular anthology in English for classroom use is Miguel León-Portilla's, The Broken Spears: The Aztec Accounts of the Conquest of Mexico from 1992.[22] Not surprisingly, many publications and republications of sixteenth-century accounts of the conquest of Mexico appeared around 1992, the 500th anniversary of Christopher Columbus's first voyage, when scholarly and popular interest in first encounters surged. 0.18244187533855438\n",
      "Unbeknownst to East when the film was being made, his Superman dialogue was dubbed over by Christopher Reeve.[3] 0.24474060535430908\n",
      "What was bill hosket, jr.'s position \n",
      "Energy obtained through the transfer of electrons down the ETC is used to pump protons from the mitochondrial matrix into the intermembrane space, creating an electrochemical proton gradient (ΔpH) across the inner mitochondrial membrane (IMM). This proton gradient is largely but not exclusively responsible for the mitochondrial membrane potential (ΔΨM). It allows ATP synthase to use the flow of H+ through the enzyme back into the matrix to generate ATP from adenosine diphosphate (ADP) and inorganic phosphate. Complex I (NADH coenzyme Q reductase; labeled I) accepts electrons from the Krebs cycle electron carrier nicotinamide adenine dinucleotide (NADH), and passes them to coenzyme Q (ubiquinone; labeled Q), which also receives electrons from complex II (succinate dehydrogenase; labeled II). Q passes electrons to complex III (cytochrome bc1 complex; labeled III), which passes them to cytochrome c (cyt c). Cyt c passes electrons to Complex IV (cytochrome c oxidase; labeled IV), which uses the electrons and hydrogen ions to reduce molecular oxygen to water. 0.14511513710021973\n",
      "AARP was founded in 1958 by Ethel Percy Andrus (a retired educator from California) and Leonard Davis (later the founder of the Colonial Penn Group of insurance companies).[3][4] It is a 501c4 non-profit organization which aims to \"enhance the quality of life for all as they age,\" according to its website. It also has members who are less than 50 years of age. The association advocates for social change and provides information, advocacy, and service to its members. It is an important lobbying group in the United States.[5][6] It updates special money related information and a \"fraudwatch\" on its website, to warn people of scams. Its fraudwatch includes write ups by Frank Abagnale from the FBI.[7] 0.15523561835289001\n",
      "According to the group's official history, Dr. Ethel Percy Andrus founded AARP in 1958. AARP evolved from the National Retired Teachers Association (NRTA), which Andrus had established in 1947 to promote her philosophy of productive aging, and to promote health insurance for retired teachers. After ten years, she opened the organization to all Americans over 50, creating AARP.[8] Today, the NRTA is a division within AARP.[9] 0.1554071456193924\n",
      "Most eukaryotic cells have mitochondria, which produce ATP from products of the citric acid cycle, fatty acid oxidation, and amino acid oxidation. At the mitochondrial inner membrane, electrons from NADH and FADH2 pass through the electron transport chain to oxygen, which is reduced to water. The electron transport chain comprises an enzymatic series of electron donors and acceptors. Each electron donor will pass electrons to a more electronegative acceptor, which in turn donates these electrons to another acceptor, a process that continues down the series until electrons are passed to oxygen, the most electronegative and terminal electron acceptor in the chain. Passage of electrons between donor and acceptor releases energy, which is used to generate a proton gradient across the mitochondrial membrane by actively \"pumping\" protons into the intermembrane space, producing a thermodynamic state that has the potential to do work. The entire process is called oxidative phosphorylation, since ADP is phosphorylated to ATP using the energy of hydrogen oxidation in many steps. 0.22181910276412964\n",
      "Pink performed \"The Star-Spangled Banner\",[5] while Leslie Odom Jr. sang \"America the Beautiful\".[119][120] Pink spit out a throat lozenge shortly before singing the anthem, later verified after many commentators thought she had spit out a piece of gum.[121] She reported being ill with flu symptoms during her performance.[122] No players were observed kneeling during the national anthem, in contrast to the protests that happened earlier in the 2016 and 2017 seasons.[123] 0.18015426397323608\n",
      "what is a live action action comedy film produce by spyglass entertainment\n",
      "The building's architect, Rafael Viñoly, also designed the Vdara hotel in Las Vegas which reportedly has a similar sunlight reflection problem that some employees called the \"Vdara death ray\".[31] The glass has since been covered with a non-reflective film.[32] 0.15289711952209473\n",
      "A mosaic from Tusculum depicting Athena, 3rd century AD 0.17652638256549835\n",
      "A mosaic of young boys hunting from the Villa Romana del Casale, Roman Sicily, 4th century AD 0.19115006923675537\n",
      "Mosaic of Aphrodite from Pompeii 0.21461047232151031\n",
      "Roman fresco from Pompeii showing a Maenad in silk dress, 1st century AD 0.18104910850524902\n",
      "Which genre is teri meri kahaani under\n",
      "In 1456, Ottoman Turkish forces invaded Athens and laid siege to a Florentine army defending the Acropolis until June 1458, when it surrendered to the Turks.[86] The Turks may have briefly restored the Parthenon to the Greek Orthodox Christians for continued use as a church.[87] Some time before the close of the fifteenth century, the Parthenon became a mosque.[88][89] 0.1480078250169754\n",
      "Showing that solitary confinement constitutes cruel and unusual punishment has proven difficult for inmates and their attorneys. The Supreme Court requires ‘extreme deprivations’ in order to have merits for a ‘conditions-of-confinement claim’ and courts have also held that inmates are only protected against “certain kinds of extreme deprivations” by the Eighth Amendment.[82] In ‘‘Farmer v. Brennan’’, the Supreme Court set two requirements that must be fulfilled in order to challenge solitary confinement as “cruel and unusual”.[82] First, prisoners must show that a “substantial risk of serious harm to inmates” and second, that the prison officials were “deliberately indifferent” to such risk.[82] To prove a prison official’s “deliberate indifference,” the prisoner must “show evidence that the official was ‘actually’ aware of a prisoner’s serious need and chose to ignore it”.[46] Since the psychological impact of solitary confinement is not believed to be “objectively” cruel and unusual within the U.S. legal system, and because it is difficult to establish that prison officials are “indifferent” to prisoner health and safety, inmates and attorneys alleging these two requirements have faced limited success. 0.17577090859413147\n",
      "The Norfolk-Virginia Beach area is served by a variety of radio stations on the FM and AM dials, with towers located around the Hampton Roads area.[87] 0.15099948644638062\n",
      "On a brighter note for the British, three Vickers Wellington torpedo night bombers of No.38 Squadron destroyed the oil tanker Tergestea at Tobruk[62] and Bristol Beaufort torpedo bombers of No. 42 Squadron RAF, attached to No. 47 Squadron, sank the tanker Proserpina at Tobruk, removing the last hope for refuelling Rommel's army. Rommel himself noted in his diary that with the sinking of Tergestea and Proserpina the battle was lost.[citation needed] 0.1733078807592392\n",
      " 0.17956583201885223\n",
      "what's the name of a founder of ndtv\n",
      "What's My Line? is a panel game show that originally ran in the United States on the CBS Television Network from 1950 to 1967, with several international versions and subsequent U.S. revivals. The game requires celebrity panelists to question a contestant in order to determine his or her occupation, i.e., \"line [of work],\" with panelists occasionally being called on to identify a celebrity \"mystery guest\" with specificity. It is the longest-running U.S. primetime network television game-show. Moderated by John Daly and with panelists Dorothy Kilgallen, Arlene Francis, and Bennett Cerf, What's My Line? won three Emmy Awards for \"Best Quiz or Audience Participation Show\" in 1952, 1953, and 1958 and the Golden Globe for Best TV Show in 1962.[1][2] 0.18556207418441772\n",
      "The Dewey Decimal Classification (DDC), or Dewey Decimal System, is a proprietary library classification system first published in the United States by Melvil Dewey in 1876.[1] It has been revised and expanded through 23 major editions, the latest issued in 2011, and has grown from a four-page pamphlet in 1876. It is also available in an abridged version suitable for smaller libraries. It is currently maintained by the Online Computer Library Center (OCLC), a non-profit cooperative that serves libraries. OCLC licenses access to an online version for catalogers called WebDewey. 0.20340988039970398\n",
      "ICD-10 is the 10th revision of the International Statistical Classification of Diseases and Related Health Problems (ICD), a medical classification list by the World Health Organization (WHO). It contains codes for diseases, signs and symptoms, abnormal findings, complaints, social circumstances, and external causes of injury or diseases.[1] \n",
      "Work on ICD-10 began in 1983 and was completed in 1992.[1] 0.22924712300300598\n",
      "The show popularized the phrase, \"Is it bigger than a breadbox?\" Steve Allen first posed this on January 18, 1953, and it was then refined over subsequent episodes. Soon, other panelists were asking this question as well.[11][12] On one occasion the guest was a man who made breadboxes. Allen correctly guessed the guest's occupation after Kilgallen asked, \"Is it bigger than a breadbox?\" Daly could not restrain his laughter in response to the question.[13][14] 0.19028303027153015\n",
      "The transmissions in 625-line format started in Moscow on November 4, 1948. Regular broadcasting began on June 16, 1949. Details for this standard were formalized in 1955 specification called GOST 7845-55, basic parameters for black-and-white television broadcast. In particular, frame size was set to 625 lines, frame rate to 25 frames/s interlaced, and video bandwidth to 6 MHz. These basic parameters were accepted by most countries having 50 Hz mains frequency and became the foundation of television systems presently known as PAL and SECAM. 0.20464155077934265\n",
      "who was oort cloud named after\n",
      "Lagertha is Ragnar's first wife and a shieldmaiden. Following her separation from Ragnar, Lagertha rises to become Earl of Hedeby in her own right, going by the name Earl Ingstad. Following the deaths of Ragnar and Aslaug, she becomes Queen of Kattegat. Based on the legendary Lagertha. 0.1751897931098938\n",
      "There is much speculation that Frederick inspired the creation of one of the series' main characters. When Full House was in early development in 1986 (under the working title House of Comics), the role eventually given to star John Stamos was that of Adam Cochran, one of three comedians sharing a house in San Francisco. Once the format was revised and the original pilot set to shoot, Stamos' character became Jesse Cochran (later renamed Jesse Katsopolis as a nod to Stamos's Greek ethnicity), the super-cool rock musician brother-in-law of Danny Tanner (played in the unaired pilot by John Posey, before Bob Saget became available for the role). Fitting in with the character's new image, it is believed that naming him \"Jesse\" and turning him into a rocker was inspired by the real-life persona of Frederick. However, series creator Jeff Franklin has stated that when the character was being renamed, he was reminded of Elvis Presley's twin brother Jesse, who had died at a young age. 0.23685091733932495\n",
      "Flag of the Dutch East India Company 0.20476767420768738\n",
      "Parle-G biscuits were earlier called 'Parle Gluco' Biscuits until the 1980s. The \"G\" in the name Parle-G originally stood for \"Glucose\", though a later brand slogan also stated \"G for Genius\".[3] 0.19208788871765137\n",
      "Flag of the Dutch West India Company 0.19223372638225555\n"
     ]
    }
   ],
   "source": [
    "# examine the results\n",
    "topk = 5  # show topk predictions by the model\n",
    "n = 10  # for the first n questions\n",
    "\n",
    "for q_id, answers in list(results.items())[:n]:\n",
    "    print(wd_queries[q_id])  # show WD question\n",
    "    for _id, score in list(answers.items())[:topk]:  # show topn answers retrieved by the model\n",
    "        print(nq_corpus[_id]['text'], score)  # show the retrieved passage with the score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can KG answer LM's questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Wiki questions from NQ and match them to entities and relations from WikiData KG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 4  # pick sample from the dev set\n",
    "CTC_DEPTH = 5  # size of the ctc matrix considered for search\n",
    "NPATHS = 10 # number of longest paths on the bigram graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottom up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  4,  7,  9, 10],\n",
      "        [ 0,  4,  7,  9, 10],\n",
      "        [ 0,  4,  7,  9,  6],\n",
      "        ...,\n",
      "        [ 0,  4,  7, 10,  6],\n",
      "        [ 0,  4,  7, 10,  9],\n",
      "        [ 0,  4,  7, 10,  9]])\n",
      "torch.Size([365, 5])\n"
     ]
    }
   ],
   "source": [
    "# match entity label to the ctc table\n",
    "import os\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "tokenizer = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "\n",
    "path = \"../data/dev/\"\n",
    "\n",
    "file = str(SAMPLE) + '.wav'\n",
    "speech, samplerate = sf.read(path+file)\n",
    "i = int(file.split('.')[0]) - 1\n",
    "\n",
    "input_values = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# find where s_tokens appear in the table\n",
    "ctc_table = torch.topk(logits, k=CTC_DEPTH, dim=-1)\n",
    "predicted_ids = ctc_table.indices[0]\n",
    "# predicted_ids = torch.argmax(logits, dim=-1).indices\n",
    "\n",
    "print(predicted_ids)\n",
    "print(predicted_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 4  4  4 ...  4  4  4]\n",
      " [ 7  7  7 ...  7  7  7]\n",
      " [ 9  9  9 ... 10 10 10]\n",
      " [10 10  6 ...  6  9  9]]\n",
      "(5, 365)\n",
      "[0 0 0 ... 6 9 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = np.transpose(np.array(predicted_ids))\n",
    "print(predictions)\n",
    "print(predictions.shape)\n",
    "# print(predictions[0])\n",
    "indices = predictions.flatten()\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315267\n"
     ]
    }
   ],
   "source": [
    "# predictions = np.array([[2, 0, 0, 4, 5, 5],\n",
    "#                         [4, 5, 5, 6, 6, 1]])\n",
    "# generate adjacencies\n",
    "def connect(predictions, t, k, n):\n",
    "    edges = []\n",
    "    for j in range(predictions.shape[0]):  # offset\n",
    "        if predictions[j][k] != 0:\n",
    "            edges.append([n*predictions.shape[1]+t, j*predictions.shape[1]+k])\n",
    "        else:\n",
    "            # skip to next if exists\n",
    "            if k < predictions.shape[1]-1:\n",
    "                edges.extend(connect(predictions, t, k+1, n))\n",
    "    return edges\n",
    "\n",
    "edges = []\n",
    "for t in range(predictions.shape[1]-1):  # columns\n",
    "    for n in range(predictions.shape[0]):  # rows\n",
    "        if predictions[n][t] != 0:\n",
    "            edges.extend(connect(predictions, t, t+1, n))\n",
    "            \n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28497 entity labels\n"
     ]
    }
   ],
   "source": [
    "# load entities\n",
    "import json\n",
    "\n",
    "path = '../data/'\n",
    "\n",
    "with open(path+'entities.json', 'r') as fin:\n",
    "    entities = json.load(fin)\n",
    "print(len(entities), 'entity labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "import difflib\n",
    "\n",
    "\n",
    "def get_overlap(s1, s2):\n",
    "    s = difflib.SequenceMatcher(None, s1, s2)\n",
    "    pos_a, pos_b, size = s.find_longest_match(0, len(s1), 0, len(s2)) \n",
    "    return s1[pos_a:pos_a+size]\n",
    "\n",
    "\n",
    "def match(edges, indices, query_str, tokenizer, n_paths=NPATHS):\n",
    "    query = tokenizer.tokenizer(query_str)['input_ids']\n",
    "    query = [query[i:i + 2] for i in range(0, len(query)-1, 1)]\n",
    "    # filter bigrams\n",
    "    bigrams = []\n",
    "    for e in edges:\n",
    "        bigram = [indices[e[0]], indices[e[1]]]\n",
    "        if bigram in query:\n",
    "            bigrams.append(e)\n",
    "\n",
    "    # build graph\n",
    "    DG = nx.DiGraph()\n",
    "    DG.add_edges_from(bigrams)\n",
    "    \n",
    "    # find all paths\n",
    "#     all_paths = []\n",
    "#     for (x, y) in itertools.combinations(DG.nodes, 2):\n",
    "#         for path in nx.all_simple_paths(DG, x, y):\n",
    "#             all_paths.append(path)\n",
    "#     # sort all paths\n",
    "#     all_paths.sort(key=len, reverse=True)\n",
    "    \n",
    "    all_paths = [nx.dag_longest_path(DG)]\n",
    "\n",
    "    # lookup maximum overlap between strings\n",
    "    for path in all_paths[:n_paths]:\n",
    "        word = ''.join(tokenizer.tokenizer.convert_ids_to_tokens([indices[i] for i in path]))\n",
    "        print(word)\n",
    "        overlap = get_overlap(query_str, word)\n",
    "        print(overlap)\n",
    "        return len(overlap) / len(query_str)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in what french city did antoine de fevin die \n",
      "antoine de fevin\n"
     ]
    }
   ],
   "source": [
    "# load original question\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "\n",
    "path = '../data/'\n",
    "with open(path+'annotated_wd_data_valid_answerable.txt') as fin:\n",
    "    lines = fin.readlines()\n",
    "    l = lines[SAMPLE-1]\n",
    "#         subject [tab] property [tab] object [tab] question\n",
    "    s, p, o, q = l.strip('\\n').split('\\t')\n",
    "    \n",
    "    q = re.sub(chars_to_ignore_regex, '', q).lower()\n",
    "    q = unidecode(q)\n",
    "    q = ''.join([j for i, j in enumerate(q) if j != q[i-1]])  # remove repeated letters\n",
    "    print(q)\n",
    "\n",
    "    s_label = entities[s]\n",
    "    s_label = re.sub(chars_to_ignore_regex, '', s_label).lower()\n",
    "    s_label = unidecode(s_label)\n",
    "    s_label = ''.join([j for i, j in enumerate(s_label) if j != s_label[i-1]])  # remove repeated letters\n",
    "    print(s_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antoine de fevin\n",
      "['antoine', 'de', 'fevin']\n",
      "INTOINTOINTOINE\n",
      "NTOINE\n",
      "DE\n",
      "DE\n",
      "FEVIN\n",
      "FEVIN\n",
      "0.95 words matched\n"
     ]
    }
   ],
   "source": [
    "# encode entity label\n",
    "query_str = s_label\n",
    "# query_str = 'gregor'\n",
    "print(query_str)\n",
    "\n",
    "q_words = [w for w in query_str.split() if len(w) > 1]\n",
    "print(q_words)\n",
    "\n",
    "matches = 0\n",
    "for word in q_words:\n",
    "    query_str = word.upper()\n",
    "    matches += match(edges, indices, query_str, tokenizer)\n",
    "    \n",
    "print('%.2f words matched' % (matches/len(q_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/ivi/ilps/personal/svakule/spoken_qa'\n",
    "dataset_name = 'WD18'\n",
    "model_name = \"msmarco-distilbert-base-tas-b\"\n",
    "trained_on = 'original'\n",
    "validated_on = 'original'\n",
    "\n",
    "#### Provide model save path\n",
    "model_save_path = os.path.join(\"/ivi/ilps/personal/svakule/msmarco\", \"output\", \"{}-{}-{}\".format(model_name, dataset_name, trained_on))\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 21:02:10 - Loaded 28497 Documents.\n",
      "2021-06-18 21:02:10 - Doc Example: {'text': 'Mirosław Bork', 'title': ''}\n",
      "2021-06-18 21:02:10 - Loaded 22719 Queries.\n",
      "2021-06-18 21:02:10 - Query Example: who is a musician born in detroit\n",
      "2021-06-18 21:02:10 - Loaded 28497 Documents.\n",
      "2021-06-18 21:02:10 - Doc Example: {'text': 'Mirosław Bork', 'title': ''}\n",
      "2021-06-18 21:02:10 - Loaded 2811 Queries.\n",
      "2021-06-18 21:02:10 - Query Example: What is a film directed by wiebke von carolsfeld?\n"
     ]
    }
   ],
   "source": [
    "# load our dataset for training\n",
    "# KGQA dataset from https://github.com/askplatypus/wikidata-simplequestions\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "def load_data(split='valid', questions='original'):\n",
    "    query_path = os.path.join(data_path, dataset_name, \"%s_%s.jsonl\" % (split, questions))  # original text questions\n",
    "    # query_path = data_path + dataset + \"wav2vec2-base-960h.jsonl\"  # questions transcribed from synthethised speech\n",
    "    qrels_path = os.path.join(data_path, dataset_name, \"%s.tsv\" % split)\n",
    "    corpus_path = os.path.join(data_path, dataset_name, \"entities.jsonl\")\n",
    "    return GenericDataLoader(corpus_file=corpus_path, query_file=query_path, qrels_file=qrels_path).load_custom()\n",
    "\n",
    "corpus, queries, qrels = load_data(split='train', questions=trained_on)\n",
    "dev_corpus, dev_queries, dev_qrels = load_data(split='valid', questions=validated_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupt queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 21:02:10 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n",
      "2021-06-18 21:02:10 - Did not find folder msmarco-distilbert-base-tas-b\n",
      "2021-06-18 21:02:10 - Search model on server: http://sbert.net/models/msmarco-distilbert-base-tas-b.zip\n",
      "2021-06-18 21:02:10 - Load SentenceTransformer from folder: /home/svakule/.cache/torch/sentence_transformers/sbert.net_models_msmarco-distilbert-base-tas-b\n",
      "2021-06-18 21:02:11 - Use pytorch device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60b8ae6e4eb4436a79a8cba6ec9acb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Adding Input Examples', max=1420.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-06-18 21:02:11 - Loaded 22719 training pairs.\n",
      "2021-06-18 21:02:11 - eval set contains 28497 documents and 2811 queries\n",
      "2021-06-18 21:02:11 - Starting to Train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e06afad3b274e6c814e3f4bcd87ccdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeaf2d78926425a83f23be8b1679ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1420.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-06-18 21:04:29 - Information Retrieval Evaluation on eval dataset after epoch 0:\n",
      "2021-06-18 21:04:38 - Queries: 2811\n",
      "2021-06-18 21:04:38 - Corpus: 28497\n",
      "\n",
      "2021-06-18 21:04:38 - Score-Function: cos_sim\n",
      "2021-06-18 21:04:38 - Accuracy@1: 95.30%\n",
      "2021-06-18 21:04:38 - Accuracy@3: 98.04%\n",
      "2021-06-18 21:04:38 - Accuracy@5: 98.26%\n",
      "2021-06-18 21:04:38 - Accuracy@10: 98.51%\n",
      "2021-06-18 21:04:38 - Precision@1: 95.30%\n",
      "2021-06-18 21:04:38 - Precision@3: 32.68%\n",
      "2021-06-18 21:04:38 - Precision@5: 19.65%\n",
      "2021-06-18 21:04:38 - Precision@10: 9.85%\n",
      "2021-06-18 21:04:38 - Recall@1: 95.30%\n",
      "2021-06-18 21:04:38 - Recall@3: 98.04%\n",
      "2021-06-18 21:04:38 - Recall@5: 98.26%\n",
      "2021-06-18 21:04:38 - Recall@10: 98.51%\n",
      "2021-06-18 21:04:38 - MRR@10: 0.9671\n",
      "2021-06-18 21:04:38 - NDCG@10: 0.9716\n",
      "2021-06-18 21:04:38 - MAP@100: 0.9673\n",
      "2021-06-18 21:04:38 - Score-Function: dot_score\n",
      "2021-06-18 21:04:38 - Accuracy@1: 95.70%\n",
      "2021-06-18 21:04:38 - Accuracy@3: 98.04%\n",
      "2021-06-18 21:04:38 - Accuracy@5: 98.22%\n",
      "2021-06-18 21:04:38 - Accuracy@10: 98.51%\n",
      "2021-06-18 21:04:38 - Precision@1: 95.70%\n",
      "2021-06-18 21:04:38 - Precision@3: 32.68%\n",
      "2021-06-18 21:04:38 - Precision@5: 19.64%\n",
      "2021-06-18 21:04:38 - Precision@10: 9.85%\n",
      "2021-06-18 21:04:38 - Recall@1: 95.70%\n",
      "2021-06-18 21:04:38 - Recall@3: 98.04%\n",
      "2021-06-18 21:04:38 - Recall@5: 98.22%\n",
      "2021-06-18 21:04:38 - Recall@10: 98.51%\n",
      "2021-06-18 21:04:38 - MRR@10: 0.9689\n",
      "2021-06-18 21:04:38 - NDCG@10: 0.9730\n",
      "2021-06-18 21:04:38 - MAP@100: 0.9691\n",
      "2021-06-18 21:04:38 - Save model to /ivi/ilps/personal/svakule/msmarco/output/msmarco-distilbert-base-tas-b-WD18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample training script from https://github.com/UKPLab/beir/blob/main/examples/retrieval/training/train_sbert.py\n",
    "from sentence_transformers import losses, models, SentenceTransformer\n",
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.train import TrainRetriever\n",
    "import pathlib, os\n",
    "\n",
    "#### Provide any sentence-transformers or HF model\n",
    "# model_name = \"distilbert-base-uncased\" \n",
    "# word_embedding_model = models.Transformer(model_name, max_seq_length=350)\n",
    "# pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "# model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "#### Or provide pretrained sentence-transformer model\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "retriever = TrainRetriever(model=model, batch_size=16)\n",
    "\n",
    "#### Prepare training samples\n",
    "train_samples = retriever.load_train(corpus, queries, qrels)\n",
    "train_dataloader = retriever.prepare_train(train_samples, shuffle=True)\n",
    "\n",
    "#### Training SBERT with cosine-product\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=retriever.model)\n",
    "#### training SBERT with dot-product\n",
    "# train_loss = losses.MultipleNegativesRankingLoss(model=retriever.model, similarity_fct=util.dot_score)\n",
    "\n",
    "#### Prepare dev evaluator\n",
    "ir_evaluator = retriever.load_ir_evaluator(dev_corpus, dev_queries, dev_qrels)\n",
    "\n",
    "#### If no dev set is present from above use dummy evaluator\n",
    "# ir_evaluator = retriever.load_dummy_evaluator()\n",
    "\n",
    "#### Configure Train params\n",
    "num_epochs = 1\n",
    "evaluation_steps = 5000\n",
    "warmup_steps = int(len(train_samples) * num_epochs / retriever.batch_size * 0.1)\n",
    "\n",
    "retriever.fit(train_objectives=[(train_dataloader, train_loss)], \n",
    "                evaluator=ir_evaluator, \n",
    "                epochs=num_epochs,\n",
    "                output_path=model_save_path,\n",
    "                warmup_steps=warmup_steps,\n",
    "                evaluation_steps=evaluation_steps,\n",
    "                use_amp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
